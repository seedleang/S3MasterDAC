{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMAL // Mécanismes d'attention\n",
    "                        notebook n°1 sur 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le travail dépend de la base IMDB qui contient des critiques de films. Le but est d'associer une classe (positif, négatif) à ces critiques. Pour cela, le mieux est de prendre en compte les sentiments exprimés dans les phrases isolées ; or le sens est quelque chose de diffus, comment peut-on savoir où regarder, à quels mots les associer ?  \n",
    "\n",
    "Ce problème est résolu grâce aux mécanismes d'attention. Ils permettent à un modèle d'apprendre à diriger son intérêt vers des points pertinents en même temps qu'il s'assure de la qualité des classifications.  \n",
    "\n",
    "https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //////////////////////////////////////////////////////////////////////////////////////////////// <useful libraries> ////\n",
    "\n",
    "# Ne pas oublier d'executer dans le shell avant de lancer python :\n",
    "# source /users/Enseignants/piwowarski/venv/amal/3.7/bin/activate\n",
    "\n",
    "from tme9models import *\n",
    "from tme9training import *\n",
    "from tme9dataset import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%load_ext tensorboard\n",
    "\n",
    "# /////////////////////////////////////////////////////////////////////////////////////////////// </useful libraries> ////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des sorties du classifieur : torch.Size([64, 2]) \n",
      "et de la sortie des attentions : torch.Size([754, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "# ////////////////////////////////////////////////////////////////////////////////////////////////// <quick testing> ////\n",
    "\n",
    "# Récupération d'un batch seul pour les tests\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "na = NaiveAttention(50,2).to(device)\n",
    "sa = SimpleAttention(50,2).to(device)\n",
    "fa = FurtherAttention(50,2).to(device)\n",
    "la = LSTMAttention(50,2).to(device)\n",
    "\n",
    "y = sa(batch[0])\n",
    "print(\"Taille des sorties du classifieur :\", y[0].shape, \"\\net de la sortie des attentions :\", y[1].shape)\n",
    "\n",
    "# ///////////////////////////////////////////////////////////////////////////////////////////////// </quick testing> ////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "//////////////////// Attention-based LinNet : naive baseline /////////////////\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef1d4de22da4c6eb3844ed07c3d2af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: \t\ttrain 0.692788302898407 \t\ttest 0.6871360540390015\n",
      "ACCURACY: \ttrain 0.5276041666666667 \t\ttest 0.616426282051282\n",
      "\n",
      "LOSS: \t\ttrain 0.6834448575973511 \t\ttest 0.6797183752059937\n",
      "ACCURACY: \ttrain 0.6122996794871794 \t\ttest 0.6495592948717949\n",
      "\n",
      "LOSS: \t\ttrain 0.6762170195579529 \t\ttest 0.6731992363929749\n",
      "ACCURACY: \ttrain 0.641426282051282 \t\ttest 0.6560496794871795\n",
      "\n",
      "LOSS: \t\ttrain 0.6698512434959412 \t\ttest 0.6676980257034302\n",
      "ACCURACY: \ttrain 0.6553685897435897 \t\ttest 0.6552483974358975\n",
      "\n",
      "LOSS: \t\ttrain 0.6641855835914612 \t\ttest 0.6623219847679138\n",
      "ACCURACY: \ttrain 0.6614182692307692 \t\ttest 0.6623798076923076\n",
      "\n",
      "LOSS: \t\ttrain 0.6591483950614929 \t\ttest 0.6577063202857971\n",
      "ACCURACY: \ttrain 0.6636618589743589 \t\ttest 0.6639022435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.6546140909194946 \t\ttest 0.6534661650657654\n",
      "ACCURACY: \ttrain 0.666786858974359 \t\ttest 0.6619391025641026\n",
      "\n",
      "LOSS: \t\ttrain 0.6503522396087646 \t\ttest 0.6496816873550415\n",
      "ACCURACY: \ttrain 0.6706730769230769 \t\ttest 0.6642227564102564\n",
      "\n",
      "LOSS: \t\ttrain 0.6465476751327515 \t\ttest 0.6469326615333557\n",
      "ACCURACY: \ttrain 0.6693108974358974 \t\ttest 0.6659054487179488\n",
      "\n",
      "LOSS: \t\ttrain 0.643017053604126 \t\ttest 0.6429314017295837\n",
      "ACCURACY: \ttrain 0.6748397435897436 \t\ttest 0.6697115384615384\n",
      "\n",
      "LOSS: \t\ttrain 0.6398643255233765 \t\ttest 0.6399418711662292\n",
      "ACCURACY: \ttrain 0.6753205128205129 \t\ttest 0.6717147435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.6366187334060669 \t\ttest 0.6377971172332764\n",
      "ACCURACY: \ttrain 0.6738782051282052 \t\ttest 0.6728365384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.6339011192321777 \t\ttest 0.6348560452461243\n",
      "ACCURACY: \ttrain 0.6791266025641025 \t\ttest 0.6685897435897435\n",
      "\n",
      "LOSS: \t\ttrain 0.6312252283096313 \t\ttest 0.6321905255317688\n",
      "ACCURACY: \ttrain 0.6796875 \t\ttest 0.6749599358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.628578782081604 \t\ttest 0.629697322845459\n",
      "ACCURACY: \ttrain 0.6801282051282052 \t\ttest 0.6774439102564103\n",
      "\n",
      "LOSS: \t\ttrain 0.6263555288314819 \t\ttest 0.6276167631149292\n",
      "ACCURACY: \ttrain 0.6840544871794871 \t\ttest 0.6770032051282051\n",
      "\n",
      "LOSS: \t\ttrain 0.6241816878318787 \t\ttest 0.6257690787315369\n",
      "ACCURACY: \ttrain 0.6841346153846154 \t\ttest 0.6797275641025641\n",
      "\n",
      "LOSS: \t\ttrain 0.6219709515571594 \t\ttest 0.6240569353103638\n",
      "ACCURACY: \ttrain 0.6859375 \t\ttest 0.6807692307692308\n",
      "\n",
      "LOSS: \t\ttrain 0.6199842095375061 \t\ttest 0.621375322341919\n",
      "ACCURACY: \ttrain 0.6876201923076923 \t\ttest 0.6813701923076924\n",
      "\n",
      "LOSS: \t\ttrain 0.6180933713912964 \t\ttest 0.6202317476272583\n",
      "ACCURACY: \ttrain 0.6882211538461539 \t\ttest 0.6837740384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.6161569356918335 \t\ttest 0.6178070902824402\n",
      "ACCURACY: \ttrain 0.6900240384615385 \t\ttest 0.6850160256410256\n",
      "\n",
      "LOSS: \t\ttrain 0.6142975091934204 \t\ttest 0.6161261796951294\n",
      "ACCURACY: \ttrain 0.6913060897435898 \t\ttest 0.6870993589743589\n",
      "\n",
      "LOSS: \t\ttrain 0.6127376556396484 \t\ttest 0.6144446730613708\n",
      "ACCURACY: \ttrain 0.6936298076923076 \t\ttest 0.6876602564102564\n",
      "\n",
      "LOSS: \t\ttrain 0.6110966205596924 \t\ttest 0.6129361987113953\n",
      "ACCURACY: \ttrain 0.692988782051282 \t\ttest 0.689022435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.6092579364776611 \t\ttest 0.6125493049621582\n",
      "ACCURACY: \ttrain 0.693790064102564 \t\ttest 0.6836538461538462\n",
      "\n",
      "LOSS: \t\ttrain 0.6078140735626221 \t\ttest 0.6098536849021912\n",
      "ACCURACY: \ttrain 0.6954727564102564 \t\ttest 0.6911057692307693\n",
      "\n",
      "LOSS: \t\ttrain 0.6063341498374939 \t\ttest 0.6084673404693604\n",
      "ACCURACY: \ttrain 0.6956330128205128 \t\ttest 0.6915865384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.604948878288269 \t\ttest 0.6070943474769592\n",
      "ACCURACY: \ttrain 0.6950721153846153 \t\ttest 0.6927884615384615\n",
      "\n",
      "LOSS: \t\ttrain 0.6035382747650146 \t\ttest 0.6058776378631592\n",
      "ACCURACY: \ttrain 0.6970753205128205 \t\ttest 0.6941506410256411\n",
      "\n",
      "LOSS: \t\ttrain 0.6021010875701904 \t\ttest 0.6052967309951782\n",
      "ACCURACY: \ttrain 0.6995592948717949 \t\ttest 0.6932692307692307\n",
      "\n",
      "LOSS: \t\ttrain 0.6007339954376221 \t\ttest 0.603165328502655\n",
      "ACCURACY: \ttrain 0.6989983974358974 \t\ttest 0.6963141025641025\n",
      "\n",
      "LOSS: \t\ttrain 0.599550724029541 \t\ttest 0.6022466421127319\n",
      "ACCURACY: \ttrain 0.7009615384615384 \t\ttest 0.6961939102564103\n",
      "\n",
      "LOSS: \t\ttrain 0.5983045101165771 \t\ttest 0.6008015871047974\n",
      "ACCURACY: \ttrain 0.7026842948717948 \t\ttest 0.6977564102564102\n",
      "\n",
      "LOSS: \t\ttrain 0.5971459746360779 \t\ttest 0.5996968150138855\n",
      "ACCURACY: \ttrain 0.7027644230769231 \t\ttest 0.6984375\n",
      "\n",
      "LOSS: \t\ttrain 0.5958802103996277 \t\ttest 0.5987802147865295\n",
      "ACCURACY: \ttrain 0.7040064102564103 \t\ttest 0.6993990384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.5946120023727417 \t\ttest 0.5975531339645386\n",
      "ACCURACY: \ttrain 0.7034054487179487 \t\ttest 0.7003205128205128\n",
      "\n",
      "LOSS: \t\ttrain 0.5935916304588318 \t\ttest 0.5973248481750488\n",
      "ACCURACY: \ttrain 0.7061698717948718 \t\ttest 0.697636217948718\n",
      "\n",
      "LOSS: \t\ttrain 0.5925838351249695 \t\ttest 0.5952832102775574\n",
      "ACCURACY: \ttrain 0.7054887820512821 \t\ttest 0.7014423076923076\n",
      "\n",
      "LOSS: \t\ttrain 0.5913468599319458 \t\ttest 0.5951182246208191\n",
      "ACCURACY: \ttrain 0.7070512820512821 \t\ttest 0.6992788461538462\n",
      "\n",
      "LOSS: \t\ttrain 0.5903372168540955 \t\ttest 0.5931262373924255\n",
      "ACCURACY: \ttrain 0.7053685897435897 \t\ttest 0.7034054487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.5893808603286743 \t\ttest 0.5922448635101318\n",
      "ACCURACY: \ttrain 0.7069711538461538 \t\ttest 0.7041266025641025\n",
      "\n",
      "LOSS: \t\ttrain 0.5885476469993591 \t\ttest 0.5914389491081238\n",
      "ACCURACY: \ttrain 0.708974358974359 \t\ttest 0.7046073717948718\n",
      "\n",
      "LOSS: \t\ttrain 0.5874245166778564 \t\ttest 0.5906305909156799\n",
      "ACCURACY: \ttrain 0.7096153846153846 \t\ttest 0.7052884615384616\n",
      "\n",
      "LOSS: \t\ttrain 0.5865432620048523 \t\ttest 0.58966064453125\n",
      "ACCURACY: \ttrain 0.7104166666666667 \t\ttest 0.7052083333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.5854195356369019 \t\ttest 0.5886508822441101\n",
      "ACCURACY: \ttrain 0.7110977564102564 \t\ttest 0.7060096153846154\n",
      "\n",
      "LOSS: \t\ttrain 0.5847148299217224 \t\ttest 0.5877091884613037\n",
      "ACCURACY: \ttrain 0.7113782051282052 \t\ttest 0.7073317307692307\n",
      "\n",
      "LOSS: \t\ttrain 0.5838419198989868 \t\ttest 0.5870419144630432\n",
      "ACCURACY: \ttrain 0.7103766025641025 \t\ttest 0.7071714743589743\n",
      "\n",
      "LOSS: \t\ttrain 0.5827058553695679 \t\ttest 0.5862119793891907\n",
      "ACCURACY: \ttrain 0.7110176282051283 \t\ttest 0.7076522435897435\n",
      "\n",
      "LOSS: \t\ttrain 0.5820088982582092 \t\ttest 0.5855571627616882\n",
      "ACCURACY: \ttrain 0.7122195512820513 \t\ttest 0.7071714743589743\n",
      "\n",
      "LOSS: \t\ttrain 0.5810881853103638 \t\ttest 0.5844033360481262\n",
      "ACCURACY: \ttrain 0.7145833333333333 \t\ttest 0.7094951923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.5804957151412964 \t\ttest 0.583593487739563\n",
      "ACCURACY: \ttrain 0.7137419871794872 \t\ttest 0.7098557692307692\n",
      "\n",
      "LOSS: \t\ttrain 0.5795001983642578 \t\ttest 0.5829193592071533\n",
      "ACCURACY: \ttrain 0.7123397435897436 \t\ttest 0.7095352564102564\n",
      "\n",
      "LOSS: \t\ttrain 0.5789006352424622 \t\ttest 0.5821183919906616\n",
      "ACCURACY: \ttrain 0.7146233974358974 \t\ttest 0.7096554487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.5781124830245972 \t\ttest 0.5815332531929016\n",
      "ACCURACY: \ttrain 0.7148237179487179 \t\ttest 0.7099759615384615\n",
      "\n",
      "LOSS: \t\ttrain 0.5772057175636292 \t\ttest 0.580835223197937\n",
      "ACCURACY: \ttrain 0.7163461538461539 \t\ttest 0.7107371794871795\n",
      "\n",
      "LOSS: \t\ttrain 0.5764121413230896 \t\ttest 0.5801092982292175\n",
      "ACCURACY: \ttrain 0.715625 \t\ttest 0.7112179487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.5759949684143066 \t\ttest 0.5795007944107056\n",
      "ACCURACY: \ttrain 0.7151842948717949 \t\ttest 0.7112980769230769\n",
      "\n",
      "LOSS: \t\ttrain 0.5752383470535278 \t\ttest 0.5786334276199341\n",
      "ACCURACY: \ttrain 0.7157051282051282 \t\ttest 0.7127804487179488\n",
      "\n",
      "LOSS: \t\ttrain 0.5743532180786133 \t\ttest 0.5783402919769287\n",
      "ACCURACY: \ttrain 0.717227564102564 \t\ttest 0.7121394230769231\n",
      "\n",
      "LOSS: \t\ttrain 0.5735782980918884 \t\ttest 0.5779407024383545\n",
      "ACCURACY: \ttrain 0.7173477564102564 \t\ttest 0.7137419871794872\n",
      "\n",
      "LOSS: \t\ttrain 0.5731589198112488 \t\ttest 0.5770730376243591\n",
      "ACCURACY: \ttrain 0.7192307692307692 \t\ttest 0.7133012820512821\n",
      "\n",
      "LOSS: \t\ttrain 0.5725398659706116 \t\ttest 0.5760670900344849\n",
      "ACCURACY: \ttrain 0.7168669871794872 \t\ttest 0.7147035256410257\n",
      "\n",
      "LOSS: \t\ttrain 0.5718263983726501 \t\ttest 0.5756675601005554\n",
      "ACCURACY: \ttrain 0.7173076923076923 \t\ttest 0.7157451923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.5712677836418152 \t\ttest 0.5749868750572205\n",
      "ACCURACY: \ttrain 0.7199519230769231 \t\ttest 0.7163862179487179\n",
      "\n",
      "LOSS: \t\ttrain 0.5707250237464905 \t\ttest 0.5743429064750671\n",
      "ACCURACY: \ttrain 0.7194310897435897 \t\ttest 0.7159455128205128\n",
      "\n",
      "LOSS: \t\ttrain 0.5699726939201355 \t\ttest 0.5742562413215637\n",
      "ACCURACY: \ttrain 0.7203926282051282 \t\ttest 0.7128605769230769\n",
      "\n",
      "LOSS: \t\ttrain 0.5693124532699585 \t\ttest 0.5737738609313965\n",
      "ACCURACY: \ttrain 0.7208333333333333 \t\ttest 0.7130208333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.5686870813369751 \t\ttest 0.572709858417511\n",
      "ACCURACY: \ttrain 0.7211137820512821 \t\ttest 0.7173878205128205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: \t\ttrain 0.5681400299072266 \t\ttest 0.5721026659011841\n",
      "ACCURACY: \ttrain 0.721073717948718 \t\ttest 0.7170673076923076\n",
      "\n",
      "LOSS: \t\ttrain 0.567707359790802 \t\ttest 0.5719293355941772\n",
      "ACCURACY: \ttrain 0.7226362179487179 \t\ttest 0.7144230769230769\n",
      "\n",
      "LOSS: \t\ttrain 0.5669922232627869 \t\ttest 0.5712614059448242\n",
      "ACCURACY: \ttrain 0.7227564102564102 \t\ttest 0.7158253205128206\n",
      "\n",
      "LOSS: \t\ttrain 0.566495418548584 \t\ttest 0.5703666806221008\n",
      "ACCURACY: \ttrain 0.7221955128205129 \t\ttest 0.7187099358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.5659566521644592 \t\ttest 0.5705655217170715\n",
      "ACCURACY: \ttrain 0.7243189102564103 \t\ttest 0.7157451923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.5652347207069397 \t\ttest 0.5703115463256836\n",
      "ACCURACY: \ttrain 0.7229166666666667 \t\ttest 0.7153846153846154\n",
      "\n",
      "LOSS: \t\ttrain 0.5650387406349182 \t\ttest 0.5692270994186401\n",
      "ACCURACY: \ttrain 0.7241987179487179 \t\ttest 0.7191506410256411\n",
      "\n",
      "LOSS: \t\ttrain 0.5644022226333618 \t\ttest 0.5686797499656677\n",
      "ACCURACY: \ttrain 0.7241185897435898 \t\ttest 0.7185096153846153\n",
      "\n",
      "LOSS: \t\ttrain 0.5637531280517578 \t\ttest 0.5682509541511536\n",
      "ACCURACY: \ttrain 0.7240384615384615 \t\ttest 0.7180689102564103\n",
      "\n",
      "LOSS: \t\ttrain 0.5634296536445618 \t\ttest 0.5685870051383972\n",
      "ACCURACY: \ttrain 0.7252403846153846 \t\ttest 0.7150641025641026\n",
      "\n",
      "LOSS: \t\ttrain 0.562928318977356 \t\ttest 0.567206621170044\n",
      "ACCURACY: \ttrain 0.724599358974359 \t\ttest 0.7188301282051283\n",
      "\n",
      "LOSS: \t\ttrain 0.562633216381073 \t\ttest 0.5666964650154114\n",
      "ACCURACY: \ttrain 0.7251201923076923 \t\ttest 0.7201522435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.561802327632904 \t\ttest 0.5668444037437439\n",
      "ACCURACY: \ttrain 0.727323717948718 \t\ttest 0.7181089743589744\n",
      "\n",
      "LOSS: \t\ttrain 0.5615465641021729 \t\ttest 0.5657854080200195\n",
      "ACCURACY: \ttrain 0.7247195512820512 \t\ttest 0.7209134615384616\n",
      "\n",
      "LOSS: \t\ttrain 0.5610789656639099 \t\ttest 0.5660728216171265\n",
      "ACCURACY: \ttrain 0.7258413461538461 \t\ttest 0.7183493589743589\n",
      "\n",
      "LOSS: \t\ttrain 0.560880184173584 \t\ttest 0.5648736357688904\n",
      "ACCURACY: \ttrain 0.7256410256410256 \t\ttest 0.7212339743589744\n",
      "\n",
      "LOSS: \t\ttrain 0.5603318810462952 \t\ttest 0.5654369592666626\n",
      "ACCURACY: \ttrain 0.7271233974358975 \t\ttest 0.7175881410256411\n",
      "\n",
      "LOSS: \t\ttrain 0.5599651336669922 \t\ttest 0.5647432804107666\n",
      "ACCURACY: \ttrain 0.7267628205128205 \t\ttest 0.71875\n",
      "\n",
      "LOSS: \t\ttrain 0.5594907402992249 \t\ttest 0.5634926557540894\n",
      "ACCURACY: \ttrain 0.7269230769230769 \t\ttest 0.7213942307692308\n",
      "\n",
      "LOSS: \t\ttrain 0.5588803887367249 \t\ttest 0.5633431673049927\n",
      "ACCURACY: \ttrain 0.7262019230769231 \t\ttest 0.7214342948717949\n",
      "\n",
      "LOSS: \t\ttrain 0.5585576891899109 \t\ttest 0.5632174611091614\n",
      "ACCURACY: \ttrain 0.7277243589743589 \t\ttest 0.7209535256410257\n",
      "\n",
      "LOSS: \t\ttrain 0.5580306649208069 \t\ttest 0.5625698566436768\n",
      "ACCURACY: \ttrain 0.7276041666666667 \t\ttest 0.7215945512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.5577309131622314 \t\ttest 0.5620831251144409\n",
      "ACCURACY: \ttrain 0.7283253205128205 \t\ttest 0.7219551282051282\n",
      "\n",
      "LOSS: \t\ttrain 0.5573430061340332 \t\ttest 0.5619135499000549\n",
      "ACCURACY: \ttrain 0.7294070512820513 \t\ttest 0.7221153846153846\n",
      "\n",
      "LOSS: \t\ttrain 0.556939959526062 \t\ttest 0.5613170862197876\n",
      "ACCURACY: \ttrain 0.728886217948718 \t\ttest 0.7221554487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.5566296577453613 \t\ttest 0.5610501170158386\n",
      "ACCURACY: \ttrain 0.7283253205128205 \t\ttest 0.7227564102564102\n",
      "\n",
      "LOSS: \t\ttrain 0.5563288331031799 \t\ttest 0.5610262751579285\n",
      "ACCURACY: \ttrain 0.7279246794871795 \t\ttest 0.7217548076923077\n",
      "\n",
      "LOSS: \t\ttrain 0.5559731125831604 \t\ttest 0.5604654550552368\n",
      "ACCURACY: \ttrain 0.7283653846153846 \t\ttest 0.7224759615384615\n",
      "\n",
      "LOSS: \t\ttrain 0.5553953051567078 \t\ttest 0.5600977540016174\n",
      "ACCURACY: \ttrain 0.7298878205128205 \t\ttest 0.7226362179487179\n",
      "\n",
      "LOSS: \t\ttrain 0.5551190972328186 \t\ttest 0.5596477389335632\n",
      "ACCURACY: \ttrain 0.7297676282051282 \t\ttest 0.7233974358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.5546470880508423 \t\ttest 0.5594542622566223\n",
      "ACCURACY: \ttrain 0.7308092948717949 \t\ttest 0.7229567307692307\n",
      "\n",
      "LOSS: \t\ttrain 0.5545225143432617 \t\ttest 0.5600066184997559\n",
      "ACCURACY: \ttrain 0.7295673076923077 \t\ttest 0.7211137820512821\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mDone.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainAttention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "///////////////// Attention-based LinNet : basic implementation //////////////\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776a5665dc4a4feab1489443a6c6a800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: \t\ttrain 0.6848136186599731 \t\ttest 0.6799988150596619\n",
      "ACCURACY: \ttrain 0.5820913461538462 \t\ttest 0.6088541666666667\n",
      "\n",
      "LOSS: \t\ttrain 0.674388587474823 \t\ttest 0.6707136034965515\n",
      "ACCURACY: \ttrain 0.6256410256410256 \t\ttest 0.624238782051282\n",
      "\n",
      "LOSS: \t\ttrain 0.6640130877494812 \t\ttest 0.6593021154403687\n",
      "ACCURACY: \ttrain 0.654727564102564 \t\ttest 0.657051282051282\n",
      "\n",
      "LOSS: \t\ttrain 0.6511582732200623 \t\ttest 0.6449893116950989\n",
      "ACCURACY: \ttrain 0.6752003205128205 \t\ttest 0.6809294871794872\n",
      "\n",
      "LOSS: \t\ttrain 0.6339248418807983 \t\ttest 0.6253759860992432\n",
      "ACCURACY: \ttrain 0.6959134615384616 \t\ttest 0.7028445512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.6106662154197693 \t\ttest 0.6004735231399536\n",
      "ACCURACY: \ttrain 0.7204727564102564 \t\ttest 0.7235576923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.585597813129425 \t\ttest 0.5776975750923157\n",
      "ACCURACY: \ttrain 0.7377804487179487 \t\ttest 0.7348557692307692\n",
      "\n",
      "LOSS: \t\ttrain 0.5637266039848328 \t\ttest 0.5582751035690308\n",
      "ACCURACY: \ttrain 0.7471955128205128 \t\ttest 0.7425080128205128\n",
      "\n",
      "LOSS: \t\ttrain 0.5453739166259766 \t\ttest 0.5419310331344604\n",
      "ACCURACY: \ttrain 0.7565705128205128 \t\ttest 0.7494791666666667\n",
      "\n",
      "LOSS: \t\ttrain 0.530249834060669 \t\ttest 0.5280582308769226\n",
      "ACCURACY: \ttrain 0.7614983974358974 \t\ttest 0.7553285256410256\n",
      "\n",
      "LOSS: \t\ttrain 0.5180299282073975 \t\ttest 0.5162398815155029\n",
      "ACCURACY: \ttrain 0.7661458333333333 \t\ttest 0.7611378205128205\n",
      "\n",
      "LOSS: \t\ttrain 0.5077922344207764 \t\ttest 0.506812572479248\n",
      "ACCURACY: \ttrain 0.769911858974359 \t\ttest 0.7652243589743589\n",
      "\n",
      "LOSS: \t\ttrain 0.49959737062454224 \t\ttest 0.49822568893432617\n",
      "ACCURACY: \ttrain 0.7724759615384615 \t\ttest 0.7693108974358974\n",
      "\n",
      "LOSS: \t\ttrain 0.49279889464378357 \t\ttest 0.4911463260650635\n",
      "ACCURACY: \ttrain 0.775 \t\ttest 0.7719551282051282\n",
      "\n",
      "LOSS: \t\ttrain 0.4868961572647095 \t\ttest 0.4854501485824585\n",
      "ACCURACY: \ttrain 0.7766025641025641 \t\ttest 0.7747596153846154\n",
      "\n",
      "LOSS: \t\ttrain 0.4824962317943573 \t\ttest 0.4810295104980469\n",
      "ACCURACY: \ttrain 0.7779246794871795 \t\ttest 0.777724358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.47937318682670593 \t\ttest 0.4772099256515503\n",
      "ACCURACY: \ttrain 0.778125 \t\ttest 0.7801682692307692\n",
      "\n",
      "LOSS: \t\ttrain 0.4763544797897339 \t\ttest 0.4745911955833435\n",
      "ACCURACY: \ttrain 0.7800881410256411 \t\ttest 0.779727564102564\n",
      "\n",
      "LOSS: \t\ttrain 0.47411292791366577 \t\ttest 0.47206026315689087\n",
      "ACCURACY: \ttrain 0.7812099358974359 \t\ttest 0.7823317307692308\n",
      "\n",
      "LOSS: \t\ttrain 0.4722754657268524 \t\ttest 0.47026944160461426\n",
      "ACCURACY: \ttrain 0.7827323717948718 \t\ttest 0.7826522435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.4710102379322052 \t\ttest 0.46838822960853577\n",
      "ACCURACY: \ttrain 0.7832932692307693 \t\ttest 0.7839342948717949\n",
      "\n",
      "LOSS: \t\ttrain 0.4690747559070587 \t\ttest 0.46788573265075684\n",
      "ACCURACY: \ttrain 0.7849759615384615 \t\ttest 0.7818108974358975\n",
      "\n",
      "LOSS: \t\ttrain 0.46807366609573364 \t\ttest 0.4660148322582245\n",
      "ACCURACY: \ttrain 0.7845352564102565 \t\ttest 0.7853365384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.4671584963798523 \t\ttest 0.46495166420936584\n",
      "ACCURACY: \ttrain 0.7849358974358974 \t\ttest 0.7856169871794871\n",
      "\n",
      "LOSS: \t\ttrain 0.4661533236503601 \t\ttest 0.46392500400543213\n",
      "ACCURACY: \ttrain 0.7857371794871795 \t\ttest 0.7861378205128206\n",
      "\n",
      "LOSS: \t\ttrain 0.4651511311531067 \t\ttest 0.4635869860649109\n",
      "ACCURACY: \ttrain 0.7858974358974359 \t\ttest 0.7859375\n",
      "\n",
      "LOSS: \t\ttrain 0.464682012796402 \t\ttest 0.46258655190467834\n",
      "ACCURACY: \ttrain 0.7862580128205128 \t\ttest 0.786298076923077\n",
      "\n",
      "LOSS: \t\ttrain 0.46374019980430603 \t\ttest 0.46197453141212463\n",
      "ACCURACY: \ttrain 0.7861378205128206 \t\ttest 0.7875\n",
      "\n",
      "LOSS: \t\ttrain 0.46324440836906433 \t\ttest 0.4609910845756531\n",
      "ACCURACY: \ttrain 0.7861378205128206 \t\ttest 0.7877403846153846\n",
      "\n",
      "LOSS: \t\ttrain 0.46242403984069824 \t\ttest 0.46064838767051697\n",
      "ACCURACY: \ttrain 0.7865785256410256 \t\ttest 0.7865384615384615\n",
      "\n",
      "LOSS: \t\ttrain 0.4620128571987152 \t\ttest 0.4599737524986267\n",
      "ACCURACY: \ttrain 0.7866987179487179 \t\ttest 0.7880208333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.4613530933856964 \t\ttest 0.45937860012054443\n",
      "ACCURACY: \ttrain 0.7870592948717948 \t\ttest 0.7885016025641025\n",
      "\n",
      "LOSS: \t\ttrain 0.46109041571617126 \t\ttest 0.45885196328163147\n",
      "ACCURACY: \ttrain 0.788261217948718 \t\ttest 0.7885416666666667\n",
      "\n",
      "LOSS: \t\ttrain 0.46050190925598145 \t\ttest 0.4583955705165863\n",
      "ACCURACY: \ttrain 0.7871794871794872 \t\ttest 0.7885416666666667\n",
      "\n",
      "LOSS: \t\ttrain 0.45982107520103455 \t\ttest 0.4581936299800873\n",
      "ACCURACY: \ttrain 0.7879807692307692 \t\ttest 0.7882211538461539\n",
      "\n",
      "LOSS: \t\ttrain 0.45957890152931213 \t\ttest 0.4582218825817108\n",
      "ACCURACY: \ttrain 0.7880208333333333 \t\ttest 0.7883413461538461\n",
      "\n",
      "LOSS: \t\ttrain 0.4592907428741455 \t\ttest 0.45731574296951294\n",
      "ACCURACY: \ttrain 0.7886217948717948 \t\ttest 0.7890625\n",
      "\n",
      "LOSS: \t\ttrain 0.45870867371559143 \t\ttest 0.4567602872848511\n",
      "ACCURACY: \ttrain 0.7885817307692308 \t\ttest 0.7901442307692308\n",
      "\n",
      "LOSS: \t\ttrain 0.4579310715198517 \t\ttest 0.4577741026878357\n",
      "ACCURACY: \ttrain 0.7887019230769231 \t\ttest 0.7886618589743589\n",
      "\n",
      "LOSS: \t\ttrain 0.4579353630542755 \t\ttest 0.4562723636627197\n",
      "ACCURACY: \ttrain 0.7886217948717948 \t\ttest 0.7889022435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.4574832022190094 \t\ttest 0.45646172761917114\n",
      "ACCURACY: \ttrain 0.7876602564102564 \t\ttest 0.7888621794871795\n",
      "\n",
      "LOSS: \t\ttrain 0.45688316226005554 \t\ttest 0.45588287711143494\n",
      "ACCURACY: \ttrain 0.7894230769230769 \t\ttest 0.7897435897435897\n",
      "\n",
      "LOSS: \t\ttrain 0.45664194226264954 \t\ttest 0.4554502069950104\n",
      "ACCURACY: \ttrain 0.7894230769230769 \t\ttest 0.7906650641025641\n",
      "\n",
      "LOSS: \t\ttrain 0.45650243759155273 \t\ttest 0.4549223780632019\n",
      "ACCURACY: \ttrain 0.7888621794871795 \t\ttest 0.790625\n",
      "\n",
      "LOSS: \t\ttrain 0.45613759756088257 \t\ttest 0.4547315239906311\n",
      "ACCURACY: \ttrain 0.7901442307692308 \t\ttest 0.7913461538461538\n",
      "\n",
      "LOSS: \t\ttrain 0.45572683215141296 \t\ttest 0.45468151569366455\n",
      "ACCURACY: \ttrain 0.7891426282051283 \t\ttest 0.7905048076923077\n",
      "\n",
      "LOSS: \t\ttrain 0.45509958267211914 \t\ttest 0.45429423451423645\n",
      "ACCURACY: \ttrain 0.7893429487179487 \t\ttest 0.7907852564102564\n",
      "\n",
      "LOSS: \t\ttrain 0.45504823327064514 \t\ttest 0.45375195145606995\n",
      "ACCURACY: \ttrain 0.7895432692307692 \t\ttest 0.7910657051282052\n",
      "\n",
      "LOSS: \t\ttrain 0.45482030510902405 \t\ttest 0.45499756932258606\n",
      "ACCURACY: \ttrain 0.7902243589743589 \t\ttest 0.7893028846153847\n",
      "\n",
      "LOSS: \t\ttrain 0.45481252670288086 \t\ttest 0.45358455181121826\n",
      "ACCURACY: \ttrain 0.7897435897435897 \t\ttest 0.7914262820512821\n",
      "\n",
      "LOSS: \t\ttrain 0.45434051752090454 \t\ttest 0.4539906978607178\n",
      "ACCURACY: \ttrain 0.7899038461538461 \t\ttest 0.7908253205128205\n",
      "\n",
      "LOSS: \t\ttrain 0.45432430505752563 \t\ttest 0.45301562547683716\n",
      "ACCURACY: \ttrain 0.7904246794871795 \t\ttest 0.7916266025641026\n",
      "\n",
      "LOSS: \t\ttrain 0.45366886258125305 \t\ttest 0.4528549015522003\n",
      "ACCURACY: \ttrain 0.790584935897436 \t\ttest 0.7915464743589744\n",
      "\n",
      "LOSS: \t\ttrain 0.45362335443496704 \t\ttest 0.45253363251686096\n",
      "ACCURACY: \ttrain 0.7911057692307693 \t\ttest 0.7915464743589744\n",
      "\n",
      "LOSS: \t\ttrain 0.45313045382499695 \t\ttest 0.45241162180900574\n",
      "ACCURACY: \ttrain 0.7902644230769231 \t\ttest 0.791786858974359\n",
      "\n",
      "LOSS: \t\ttrain 0.4531748294830322 \t\ttest 0.45203056931495667\n",
      "ACCURACY: \ttrain 0.7918669871794872 \t\ttest 0.7923076923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.4526621997356415 \t\ttest 0.4533356726169586\n",
      "ACCURACY: \ttrain 0.7917067307692308 \t\ttest 0.7894230769230769\n",
      "\n",
      "LOSS: \t\ttrain 0.45271036028862 \t\ttest 0.4516298770904541\n",
      "ACCURACY: \ttrain 0.7916266025641026 \t\ttest 0.7924278846153846\n",
      "\n",
      "LOSS: \t\ttrain 0.45252031087875366 \t\ttest 0.45164525508880615\n",
      "ACCURACY: \ttrain 0.7909455128205128 \t\ttest 0.7924278846153846\n",
      "\n",
      "LOSS: \t\ttrain 0.4519640803337097 \t\ttest 0.4509493112564087\n",
      "ACCURACY: \ttrain 0.7916266025641026 \t\ttest 0.7927083333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.451686292886734 \t\ttest 0.4515077471733093\n",
      "ACCURACY: \ttrain 0.7918669871794872 \t\ttest 0.7920272435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.4515656530857086 \t\ttest 0.45082664489746094\n",
      "ACCURACY: \ttrain 0.7908253205128205 \t\ttest 0.7925080128205129\n",
      "\n",
      "LOSS: \t\ttrain 0.4515570402145386 \t\ttest 0.45090964436531067\n",
      "ACCURACY: \ttrain 0.7913060897435897 \t\ttest 0.7930689102564102\n",
      "\n",
      "LOSS: \t\ttrain 0.45140963792800903 \t\ttest 0.4512999951839447\n",
      "ACCURACY: \ttrain 0.7920673076923077 \t\ttest 0.7921875\n",
      "\n",
      "LOSS: \t\ttrain 0.45090538263320923 \t\ttest 0.45056137442588806\n",
      "ACCURACY: \ttrain 0.7911458333333333 \t\ttest 0.792588141025641\n",
      "\n",
      "LOSS: \t\ttrain 0.4506572484970093 \t\ttest 0.4503592550754547\n",
      "ACCURACY: \ttrain 0.7913060897435897 \t\ttest 0.7928685897435898\n",
      "\n",
      "LOSS: \t\ttrain 0.4506169259548187 \t\ttest 0.4508116543292999\n",
      "ACCURACY: \ttrain 0.791826923076923 \t\ttest 0.7924679487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.4503194987773895 \t\ttest 0.45003741979599\n",
      "ACCURACY: \ttrain 0.7925080128205129 \t\ttest 0.7928285256410257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: \t\ttrain 0.4504975378513336 \t\ttest 0.4498746991157532\n",
      "ACCURACY: \ttrain 0.7920272435897436 \t\ttest 0.7936298076923077\n",
      "\n",
      "LOSS: \t\ttrain 0.4501482844352722 \t\ttest 0.4502839148044586\n",
      "ACCURACY: \ttrain 0.7922275641025641 \t\ttest 0.7926282051282051\n",
      "\n",
      "LOSS: \t\ttrain 0.4498780071735382 \t\ttest 0.44962745904922485\n",
      "ACCURACY: \ttrain 0.7921073717948718 \t\ttest 0.79375\n",
      "\n",
      "LOSS: \t\ttrain 0.44984009861946106 \t\ttest 0.44942474365234375\n",
      "ACCURACY: \ttrain 0.7927884615384615 \t\ttest 0.7935096153846154\n",
      "\n",
      "LOSS: \t\ttrain 0.4495348036289215 \t\ttest 0.4493943154811859\n",
      "ACCURACY: \ttrain 0.7935897435897435 \t\ttest 0.7934695512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.4490576982498169 \t\ttest 0.4497293531894684\n",
      "ACCURACY: \ttrain 0.7931089743589743 \t\ttest 0.7925480769230769\n",
      "\n",
      "LOSS: \t\ttrain 0.44927147030830383 \t\ttest 0.4488200545310974\n",
      "ACCURACY: \ttrain 0.7934294871794871 \t\ttest 0.7937900641025641\n",
      "\n",
      "LOSS: \t\ttrain 0.44901642203330994 \t\ttest 0.4489074945449829\n",
      "ACCURACY: \ttrain 0.7931089743589743 \t\ttest 0.7934695512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.4487987160682678 \t\ttest 0.44914481043815613\n",
      "ACCURACY: \ttrain 0.7937900641025641 \t\ttest 0.7937099358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.44891515374183655 \t\ttest 0.44839319586753845\n",
      "ACCURACY: \ttrain 0.7940705128205128 \t\ttest 0.7938301282051282\n",
      "\n",
      "LOSS: \t\ttrain 0.448771208524704 \t\ttest 0.44832032918930054\n",
      "ACCURACY: \ttrain 0.7935096153846154 \t\ttest 0.79375\n",
      "\n",
      "LOSS: \t\ttrain 0.4485380947589874 \t\ttest 0.4481476843357086\n",
      "ACCURACY: \ttrain 0.7921875 \t\ttest 0.7937900641025641\n",
      "\n",
      "LOSS: \t\ttrain 0.4482281506061554 \t\ttest 0.44832369685173035\n",
      "ACCURACY: \ttrain 0.7935096153846154 \t\ttest 0.7939903846153846\n",
      "\n",
      "LOSS: \t\ttrain 0.4479001760482788 \t\ttest 0.44918790459632874\n",
      "ACCURACY: \ttrain 0.793349358974359 \t\ttest 0.7923477564102565\n",
      "\n",
      "LOSS: \t\ttrain 0.44796982407569885 \t\ttest 0.44837644696235657\n",
      "ACCURACY: \ttrain 0.7932291666666667 \t\ttest 0.7938701923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.447825163602829 \t\ttest 0.4487094283103943\n",
      "ACCURACY: \ttrain 0.7936698717948718 \t\ttest 0.7945112179487179\n",
      "\n",
      "LOSS: \t\ttrain 0.44799286127090454 \t\ttest 0.44774046540260315\n",
      "ACCURACY: \ttrain 0.7934695512820513 \t\ttest 0.7940705128205128\n",
      "\n",
      "LOSS: \t\ttrain 0.4477008283138275 \t\ttest 0.44809234142303467\n",
      "ACCURACY: \ttrain 0.794551282051282 \t\ttest 0.7943910256410256\n",
      "\n",
      "LOSS: \t\ttrain 0.4474066495895386 \t\ttest 0.4478619694709778\n",
      "ACCURACY: \ttrain 0.7947516025641026 \t\ttest 0.7942708333333334\n",
      "\n",
      "LOSS: \t\ttrain 0.4474160373210907 \t\ttest 0.4472564160823822\n",
      "ACCURACY: \ttrain 0.7946314102564103 \t\ttest 0.7945913461538462\n",
      "\n",
      "LOSS: \t\ttrain 0.4472450911998749 \t\ttest 0.44752445816993713\n",
      "ACCURACY: \ttrain 0.7943108974358974 \t\ttest 0.7943910256410256\n",
      "\n",
      "LOSS: \t\ttrain 0.4470405578613281 \t\ttest 0.44733548164367676\n",
      "ACCURACY: \ttrain 0.7938301282051282 \t\ttest 0.7943910256410256\n",
      "\n",
      "LOSS: \t\ttrain 0.44707393646240234 \t\ttest 0.44716203212738037\n",
      "ACCURACY: \ttrain 0.794911858974359 \t\ttest 0.7944310897435898\n",
      "\n",
      "LOSS: \t\ttrain 0.44698283076286316 \t\ttest 0.44699206948280334\n",
      "ACCURACY: \ttrain 0.7947516025641026 \t\ttest 0.7948717948717948\n",
      "\n",
      "LOSS: \t\ttrain 0.4466991722583771 \t\ttest 0.4468662440776825\n",
      "ACCURACY: \ttrain 0.7942708333333334 \t\ttest 0.7951121794871795\n",
      "\n",
      "LOSS: \t\ttrain 0.4466080665588379 \t\ttest 0.4466463327407837\n",
      "ACCURACY: \ttrain 0.7946314102564103 \t\ttest 0.7951121794871795\n",
      "\n",
      "LOSS: \t\ttrain 0.4464324414730072 \t\ttest 0.4476364254951477\n",
      "ACCURACY: \ttrain 0.7935096153846154 \t\ttest 0.7933894230769231\n",
      "\n",
      "LOSS: \t\ttrain 0.44641634821891785 \t\ttest 0.447052925825119\n",
      "ACCURACY: \ttrain 0.7940304487179487 \t\ttest 0.7944310897435898\n",
      "\n",
      "LOSS: \t\ttrain 0.446349173784256 \t\ttest 0.4468103349208832\n",
      "ACCURACY: \ttrain 0.7946314102564103 \t\ttest 0.7945913461538462\n",
      "\n",
      "LOSS: \t\ttrain 0.4463005065917969 \t\ttest 0.4461155831813812\n",
      "ACCURACY: \ttrain 0.7948317307692307 \t\ttest 0.7955128205128205\n",
      "\n",
      "LOSS: \t\ttrain 0.44580313563346863 \t\ttest 0.4473467469215393\n",
      "ACCURACY: \ttrain 0.7952724358974359 \t\ttest 0.7941907051282051\n",
      "\n",
      "LOSS: \t\ttrain 0.44603100419044495 \t\ttest 0.44623619318008423\n",
      "ACCURACY: \ttrain 0.795352564102564 \t\ttest 0.7954727564102564\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mDone.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainAttention(model=SimpleAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention avec questions et valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "///////////////// Attention-based LinNet : further improvements //////////////\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05d951424184af6acd6938e20421eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=42.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: \t\ttrain 0.5530955195426941 \t\ttest 0.5044490098953247\n",
      "ACCURACY: \ttrain 0.7233573717948718 \t\ttest 0.7489583333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.4843697249889374 \t\ttest 0.4750230312347412\n",
      "ACCURACY: \ttrain 0.7717548076923076 \t\ttest 0.7758012820512821\n",
      "\n",
      "LOSS: \t\ttrain 0.4782238006591797 \t\ttest 0.48473531007766724\n",
      "ACCURACY: \ttrain 0.7761217948717949 \t\ttest 0.7670673076923077\n",
      "\n",
      "LOSS: \t\ttrain 0.47265079617500305 \t\ttest 0.4806292653083801\n",
      "ACCURACY: \ttrain 0.7812900641025641 \t\ttest 0.7775240384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.46334418654441833 \t\ttest 0.4727323651313782\n",
      "ACCURACY: \ttrain 0.7850560897435898 \t\ttest 0.7781650641025641\n",
      "\n",
      "LOSS: \t\ttrain 0.46811383962631226 \t\ttest 0.4747752547264099\n",
      "ACCURACY: \ttrain 0.7808092948717948 \t\ttest 0.7776842948717949\n",
      "\n",
      "LOSS: \t\ttrain 0.4662545621395111 \t\ttest 0.4773558974266052\n",
      "ACCURACY: \ttrain 0.7833333333333333 \t\ttest 0.7703125\n",
      "\n",
      "LOSS: \t\ttrain 0.4624371826648712 \t\ttest 0.47015076875686646\n",
      "ACCURACY: \ttrain 0.7857371794871795 \t\ttest 0.7809695512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.45788735151290894 \t\ttest 0.4856222867965698\n",
      "ACCURACY: \ttrain 0.7873397435897436 \t\ttest 0.7768830128205129\n",
      "\n",
      "LOSS: \t\ttrain 0.45558586716651917 \t\ttest 0.47523146867752075\n",
      "ACCURACY: \ttrain 0.7903044871794872 \t\ttest 0.778125\n",
      "\n",
      "LOSS: \t\ttrain 0.45584604144096375 \t\ttest 0.48140591382980347\n",
      "ACCURACY: \ttrain 0.7899038461538461 \t\ttest 0.778485576923077\n",
      "\n",
      "LOSS: \t\ttrain 0.4538060128688812 \t\ttest 0.46421384811401367\n",
      "ACCURACY: \ttrain 0.790625 \t\ttest 0.7853766025641026\n",
      "\n",
      "LOSS: \t\ttrain 0.45017215609550476 \t\ttest 0.4828994870185852\n",
      "ACCURACY: \ttrain 0.7928685897435898 \t\ttest 0.7695913461538462\n",
      "\n",
      "LOSS: \t\ttrain 0.44712933897972107 \t\ttest 0.46443548798561096\n",
      "ACCURACY: \ttrain 0.7931089743589743 \t\ttest 0.7823717948717949\n",
      "\n",
      "LOSS: \t\ttrain 0.4521518647670746 \t\ttest 0.474823921918869\n",
      "ACCURACY: \ttrain 0.7910657051282052 \t\ttest 0.7788060897435898\n",
      "\n",
      "LOSS: \t\ttrain 0.4467940330505371 \t\ttest 0.4789816737174988\n",
      "ACCURACY: \ttrain 0.7944310897435898 \t\ttest 0.777724358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.44774651527404785 \t\ttest 0.46574923396110535\n",
      "ACCURACY: \ttrain 0.7933894230769231 \t\ttest 0.7784054487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.4469761252403259 \t\ttest 0.4723592698574066\n",
      "ACCURACY: \ttrain 0.7930689102564102 \t\ttest 0.7792067307692307\n",
      "\n",
      "LOSS: \t\ttrain 0.44743138551712036 \t\ttest 0.4654485881328583\n",
      "ACCURACY: \ttrain 0.7949519230769231 \t\ttest 0.7856169871794871\n",
      "\n",
      "LOSS: \t\ttrain 0.44835320115089417 \t\ttest 0.49135521054267883\n",
      "ACCURACY: \ttrain 0.7929887820512821 \t\ttest 0.7611378205128205\n",
      "\n",
      "LOSS: \t\ttrain 0.44472944736480713 \t\ttest 0.4944382607936859\n",
      "ACCURACY: \ttrain 0.7967147435897436 \t\ttest 0.7634214743589743\n",
      "\n",
      "LOSS: \t\ttrain 0.44439688324928284 \t\ttest 0.46863892674446106\n",
      "ACCURACY: \ttrain 0.7952724358974359 \t\ttest 0.7809695512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.4438093602657318 \t\ttest 0.48067766427993774\n",
      "ACCURACY: \ttrain 0.7954326923076923 \t\ttest 0.7791666666666667\n",
      "\n",
      "LOSS: \t\ttrain 0.43879273533821106 \t\ttest 0.46887657046318054\n",
      "ACCURACY: \ttrain 0.7993589743589744 \t\ttest 0.7810496794871795\n",
      "\n",
      "LOSS: \t\ttrain 0.4395388662815094 \t\ttest 0.4665077030658722\n",
      "ACCURACY: \ttrain 0.8006810897435898 \t\ttest 0.7846554487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.4408116936683655 \t\ttest 0.47237178683280945\n",
      "ACCURACY: \ttrain 0.796875 \t\ttest 0.7766826923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.4410470128059387 \t\ttest 0.47134506702423096\n",
      "ACCURACY: \ttrain 0.7977163461538461 \t\ttest 0.7769230769230769\n",
      "\n",
      "LOSS: \t\ttrain 0.440589964389801 \t\ttest 0.4693467617034912\n",
      "ACCURACY: \ttrain 0.7983573717948718 \t\ttest 0.780488782051282\n",
      "\n",
      "LOSS: \t\ttrain 0.44028303027153015 \t\ttest 0.47376856207847595\n",
      "ACCURACY: \ttrain 0.7980368589743589 \t\ttest 0.7786858974358974\n",
      "\n",
      "LOSS: \t\ttrain 0.4459967017173767 \t\ttest 0.4598533511161804\n",
      "ACCURACY: \ttrain 0.7959935897435897 \t\ttest 0.783213141025641\n",
      "\n",
      "LOSS: \t\ttrain 0.4357875883579254 \t\ttest 0.4684075117111206\n",
      "ACCURACY: \ttrain 0.8013621794871795 \t\ttest 0.785536858974359\n",
      "\n",
      "LOSS: \t\ttrain 0.4363032579421997 \t\ttest 0.4747278690338135\n",
      "ACCURACY: \ttrain 0.8020032051282051 \t\ttest 0.7824919871794872\n",
      "\n",
      "LOSS: \t\ttrain 0.4385763108730316 \t\ttest 0.47102728486061096\n",
      "ACCURACY: \ttrain 0.7989983974358974 \t\ttest 0.7794471153846154\n",
      "\n",
      "LOSS: \t\ttrain 0.4335310459136963 \t\ttest 0.510022759437561\n",
      "ACCURACY: \ttrain 0.8000801282051282 \t\ttest 0.760576923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.43661779165267944 \t\ttest 0.50040602684021\n",
      "ACCURACY: \ttrain 0.8001602564102565 \t\ttest 0.7693509615384615\n",
      "\n",
      "LOSS: \t\ttrain 0.4396578073501587 \t\ttest 0.46012020111083984\n",
      "ACCURACY: \ttrain 0.7999599358974359 \t\ttest 0.7836939102564102\n",
      "\n",
      "LOSS: \t\ttrain 0.4333975911140442 \t\ttest 0.4881603419780731\n",
      "ACCURACY: \ttrain 0.8022435897435898 \t\ttest 0.776963141025641\n",
      "\n",
      "LOSS: \t\ttrain 0.43789634108543396 \t\ttest 0.47478634119033813\n",
      "ACCURACY: \ttrain 0.7997596153846154 \t\ttest 0.7752403846153846\n",
      "\n",
      "LOSS: \t\ttrain 0.4348374009132385 \t\ttest 0.4777035117149353\n",
      "ACCURACY: \ttrain 0.8022836538461539 \t\ttest 0.7801682692307692\n",
      "\n",
      "LOSS: \t\ttrain 0.4341220557689667 \t\ttest 0.46956750750541687\n",
      "ACCURACY: \ttrain 0.8028846153846154 \t\ttest 0.7802083333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.4323558807373047 \t\ttest 0.47469890117645264\n",
      "ACCURACY: \ttrain 0.8033253205128205 \t\ttest 0.7738782051282052\n",
      "\n",
      "LOSS: \t\ttrain 0.4305304288864136 \t\ttest 0.4801514148712158\n",
      "ACCURACY: \ttrain 0.8044471153846153 \t\ttest 0.7811698717948717\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mDone.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainAttention(model=FurtherAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout d'une LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "//////////////////// Attention-based LinNet : adding an LSTM /////////////////\n",
      "\n",
      "Restarting from previous state.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4bdb2b81fa4e0e9b113254f0270388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[1mDone.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainAttention(model=LSTMAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régularisation par l'entropie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "///////////////// Attention-based LinNet : further improvements //////////////\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9199579af7453abb7858aab9797658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: \t\ttrain 0.885619580745697 \t\ttest 0.6911413073539734\n",
      "ACCURACY: \ttrain 0.5024839743589744 \t\ttest 0.5283253205128206\n",
      "\n",
      "LOSS: \t\ttrain 0.7710341215133667 \t\ttest 0.6897268891334534\n",
      "ACCURACY: \ttrain 0.5338141025641026 \t\ttest 0.5344951923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.752338707447052 \t\ttest 0.689031720161438\n",
      "ACCURACY: \ttrain 0.5372996794871795 \t\ttest 0.5374198717948718\n",
      "\n",
      "LOSS: \t\ttrain 0.7437063455581665 \t\ttest 0.6859720349311829\n",
      "ACCURACY: \ttrain 0.541826923076923 \t\ttest 0.5448317307692307\n",
      "\n",
      "LOSS: \t\ttrain 0.7383107542991638 \t\ttest 0.684909999370575\n",
      "ACCURACY: \ttrain 0.5443509615384615 \t\ttest 0.5449919871794872\n",
      "\n",
      "LOSS: \t\ttrain 0.7343741059303284 \t\ttest 0.6844171285629272\n",
      "ACCURACY: \ttrain 0.5464743589743589 \t\ttest 0.5498798076923077\n",
      "\n",
      "LOSS: \t\ttrain 0.7312635779380798 \t\ttest 0.6835806369781494\n",
      "ACCURACY: \ttrain 0.5467147435897436 \t\ttest 0.5455128205128205\n",
      "\n",
      "LOSS: \t\ttrain 0.728567361831665 \t\ttest 0.6830191612243652\n",
      "ACCURACY: \ttrain 0.5493990384615385 \t\ttest 0.5501602564102565\n",
      "\n",
      "LOSS: \t\ttrain 0.7263528108596802 \t\ttest 0.6830371022224426\n",
      "ACCURACY: \ttrain 0.5506810897435898 \t\ttest 0.5481169871794872\n",
      "\n",
      "LOSS: \t\ttrain 0.7241848707199097 \t\ttest 0.6820306181907654\n",
      "ACCURACY: \ttrain 0.5518830128205128 \t\ttest 0.556650641025641\n",
      "\n",
      "LOSS: \t\ttrain 0.7224670052528381 \t\ttest 0.6813710927963257\n",
      "ACCURACY: \ttrain 0.5563701923076924 \t\ttest 0.5583333333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.720510721206665 \t\ttest 0.681813657283783\n",
      "ACCURACY: \ttrain 0.5590945512820513 \t\ttest 0.5540865384615384\n",
      "\n",
      "LOSS: \t\ttrain 0.7186778783798218 \t\ttest 0.678587019443512\n",
      "ACCURACY: \ttrain 0.5620993589743589 \t\ttest 0.5612580128205128\n",
      "\n",
      "LOSS: \t\ttrain 0.7156791090965271 \t\ttest 0.6788070201873779\n",
      "ACCURACY: \ttrain 0.5649038461538461 \t\ttest 0.5630208333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.7131687998771667 \t\ttest 0.6775204539299011\n",
      "ACCURACY: \ttrain 0.5646634615384616 \t\ttest 0.560977564102564\n",
      "\n",
      "LOSS: \t\ttrain 0.7111782431602478 \t\ttest 0.6775229573249817\n",
      "ACCURACY: \ttrain 0.564463141025641 \t\ttest 0.561698717948718\n",
      "\n",
      "LOSS: \t\ttrain 0.7099758982658386 \t\ttest 0.677158534526825\n",
      "ACCURACY: \ttrain 0.5668269230769231 \t\ttest 0.5643028846153846\n",
      "\n",
      "LOSS: \t\ttrain 0.7087732553482056 \t\ttest 0.6768430471420288\n",
      "ACCURACY: \ttrain 0.568790064102564 \t\ttest 0.5643028846153846\n",
      "\n",
      "LOSS: \t\ttrain 0.707619845867157 \t\ttest 0.6762029528617859\n",
      "ACCURACY: \ttrain 0.5688701923076923 \t\ttest 0.5649839743589744\n",
      "\n",
      "LOSS: \t\ttrain 0.7066864967346191 \t\ttest 0.6763167977333069\n",
      "ACCURACY: \ttrain 0.5696714743589744 \t\ttest 0.5660657051282051\n",
      "\n",
      "LOSS: \t\ttrain 0.7057766914367676 \t\ttest 0.6756495237350464\n",
      "ACCURACY: \ttrain 0.5729967948717949 \t\ttest 0.5674679487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.704785168170929 \t\ttest 0.6764546632766724\n",
      "ACCURACY: \ttrain 0.573838141025641 \t\ttest 0.5571714743589744\n",
      "\n",
      "LOSS: \t\ttrain 0.7041240930557251 \t\ttest 0.6747425198554993\n",
      "ACCURACY: \ttrain 0.5736378205128205 \t\ttest 0.5694711538461539\n",
      "\n",
      "LOSS: \t\ttrain 0.7030154466629028 \t\ttest 0.6743369102478027\n",
      "ACCURACY: \ttrain 0.5765224358974359 \t\ttest 0.5704326923076923\n",
      "\n",
      "LOSS: \t\ttrain 0.702345073223114 \t\ttest 0.674066424369812\n",
      "ACCURACY: \ttrain 0.5766826923076923 \t\ttest 0.5713942307692308\n",
      "\n",
      "LOSS: \t\ttrain 0.701688826084137 \t\ttest 0.6733956336975098\n",
      "ACCURACY: \ttrain 0.5774038461538461 \t\ttest 0.5728365384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.7008368968963623 \t\ttest 0.6739391088485718\n",
      "ACCURACY: \ttrain 0.5780048076923077 \t\ttest 0.5768830128205128\n",
      "\n",
      "LOSS: \t\ttrain 0.7004008293151855 \t\ttest 0.6727672815322876\n",
      "ACCURACY: \ttrain 0.5797676282051282 \t\ttest 0.5738782051282051\n",
      "\n",
      "LOSS: \t\ttrain 0.6996456980705261 \t\ttest 0.6726475954055786\n",
      "ACCURACY: \ttrain 0.5780849358974359 \t\ttest 0.576161858974359\n",
      "\n",
      "LOSS: \t\ttrain 0.6989306807518005 \t\ttest 0.6721138954162598\n",
      "ACCURACY: \ttrain 0.5816907051282051 \t\ttest 0.5754807692307692\n",
      "\n",
      "LOSS: \t\ttrain 0.698210597038269 \t\ttest 0.6722629070281982\n",
      "ACCURACY: \ttrain 0.580849358974359 \t\ttest 0.5790865384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.6978460550308228 \t\ttest 0.6713643074035645\n",
      "ACCURACY: \ttrain 0.5823317307692307 \t\ttest 0.5771233974358975\n",
      "\n",
      "LOSS: \t\ttrain 0.6969572901725769 \t\ttest 0.6717016100883484\n",
      "ACCURACY: \ttrain 0.5816907051282051 \t\ttest 0.5789663461538461\n",
      "\n",
      "LOSS: \t\ttrain 0.6966412663459778 \t\ttest 0.6702061891555786\n",
      "ACCURACY: \ttrain 0.5826923076923077 \t\ttest 0.5798477564102564\n",
      "\n",
      "LOSS: \t\ttrain 0.6960835456848145 \t\ttest 0.6699526309967041\n",
      "ACCURACY: \ttrain 0.5856169871794872 \t\ttest 0.5797676282051282\n",
      "\n",
      "LOSS: \t\ttrain 0.6954011917114258 \t\ttest 0.6696802377700806\n",
      "ACCURACY: \ttrain 0.5869791666666667 \t\ttest 0.5798076923076924\n",
      "\n",
      "LOSS: \t\ttrain 0.6949126124382019 \t\ttest 0.6693159341812134\n",
      "ACCURACY: \ttrain 0.5888221153846154 \t\ttest 0.5833333333333334\n",
      "\n",
      "LOSS: \t\ttrain 0.6941424608230591 \t\ttest 0.6687570810317993\n",
      "ACCURACY: \ttrain 0.587459935897436 \t\ttest 0.5830128205128206\n",
      "\n",
      "LOSS: \t\ttrain 0.6935243606567383 \t\ttest 0.6685612797737122\n",
      "ACCURACY: \ttrain 0.5883413461538461 \t\ttest 0.5840945512820512\n",
      "\n",
      "LOSS: \t\ttrain 0.6933116912841797 \t\ttest 0.6672324538230896\n",
      "ACCURACY: \ttrain 0.590224358974359 \t\ttest 0.5843349358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.6927041411399841 \t\ttest 0.6668250560760498\n",
      "ACCURACY: \ttrain 0.5872996794871795 \t\ttest 0.5857772435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.6920158267021179 \t\ttest 0.6659478545188904\n",
      "ACCURACY: \ttrain 0.591426282051282 \t\ttest 0.5894230769230769\n",
      "\n",
      "LOSS: \t\ttrain 0.6910884976387024 \t\ttest 0.6658149361610413\n",
      "ACCURACY: \ttrain 0.5901041666666667 \t\ttest 0.5903445512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.6904302835464478 \t\ttest 0.6644685864448547\n",
      "ACCURACY: \ttrain 0.5938701923076923 \t\ttest 0.5903445512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.6897488832473755 \t\ttest 0.6636844873428345\n",
      "ACCURACY: \ttrain 0.5945913461538461 \t\ttest 0.5927483974358975\n",
      "\n",
      "LOSS: \t\ttrain 0.6891913414001465 \t\ttest 0.6628953218460083\n",
      "ACCURACY: \ttrain 0.5964342948717949 \t\ttest 0.5968349358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.6880715489387512 \t\ttest 0.6623745560646057\n",
      "ACCURACY: \ttrain 0.6004807692307692 \t\ttest 0.5947115384615385\n",
      "\n",
      "LOSS: \t\ttrain 0.6872627139091492 \t\ttest 0.6609817147254944\n",
      "ACCURACY: \ttrain 0.5977964743589743 \t\ttest 0.602323717948718\n",
      "\n",
      "LOSS: \t\ttrain 0.6862092018127441 \t\ttest 0.6602562665939331\n",
      "ACCURACY: \ttrain 0.6015625 \t\ttest 0.6010016025641025\n",
      "\n",
      "LOSS: \t\ttrain 0.685224711894989 \t\ttest 0.660010814666748\n",
      "ACCURACY: \ttrain 0.6039262820512821 \t\ttest 0.6012019230769231\n",
      "\n",
      "LOSS: \t\ttrain 0.6844243407249451 \t\ttest 0.6590977907180786\n",
      "ACCURACY: \ttrain 0.6040865384615385 \t\ttest 0.6036458333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.6834008693695068 \t\ttest 0.6590849757194519\n",
      "ACCURACY: \ttrain 0.6058894230769231 \t\ttest 0.6032051282051282\n",
      "\n",
      "LOSS: \t\ttrain 0.6825551390647888 \t\ttest 0.6576822400093079\n",
      "ACCURACY: \ttrain 0.6075721153846154 \t\ttest 0.603125\n",
      "\n",
      "LOSS: \t\ttrain 0.6815363168716431 \t\ttest 0.6569083333015442\n",
      "ACCURACY: \ttrain 0.6093349358974359 \t\ttest 0.6090144230769231\n",
      "\n",
      "LOSS: \t\ttrain 0.6802006959915161 \t\ttest 0.6559841632843018\n",
      "ACCURACY: \ttrain 0.6097756410256411 \t\ttest 0.6098958333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.6788374185562134 \t\ttest 0.6556934118270874\n",
      "ACCURACY: \ttrain 0.6127804487179487 \t\ttest 0.6092548076923077\n",
      "\n",
      "LOSS: \t\ttrain 0.6778651475906372 \t\ttest 0.6544774174690247\n",
      "ACCURACY: \ttrain 0.614423076923077 \t\ttest 0.6159054487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.6767244935035706 \t\ttest 0.6530333757400513\n",
      "ACCURACY: \ttrain 0.6167868589743589 \t\ttest 0.6143830128205128\n",
      "\n",
      "LOSS: \t\ttrain 0.6756773591041565 \t\ttest 0.6523042321205139\n",
      "ACCURACY: \ttrain 0.6161057692307692 \t\ttest 0.6155849358974359\n",
      "\n",
      "LOSS: \t\ttrain 0.6745954155921936 \t\ttest 0.6516032814979553\n",
      "ACCURACY: \ttrain 0.6185096153846154 \t\ttest 0.6180288461538461\n",
      "\n",
      "LOSS: \t\ttrain 0.6737045645713806 \t\ttest 0.6503301858901978\n",
      "ACCURACY: \ttrain 0.6221955128205128 \t\ttest 0.61875\n",
      "\n",
      "LOSS: \t\ttrain 0.6729384660720825 \t\ttest 0.6494945883750916\n",
      "ACCURACY: \ttrain 0.6232772435897436 \t\ttest 0.6203125\n",
      "\n",
      "LOSS: \t\ttrain 0.6716938018798828 \t\ttest 0.6482174396514893\n",
      "ACCURACY: \ttrain 0.6228365384615384 \t\ttest 0.6237580128205128\n",
      "\n",
      "LOSS: \t\ttrain 0.6706371903419495 \t\ttest 0.6470884084701538\n",
      "ACCURACY: \ttrain 0.6249599358974359 \t\ttest 0.6266426282051282\n",
      "\n",
      "LOSS: \t\ttrain 0.6693963408470154 \t\ttest 0.6459165811538696\n",
      "ACCURACY: \ttrain 0.6278044871794872 \t\ttest 0.630488782051282\n",
      "\n",
      "LOSS: \t\ttrain 0.6682472825050354 \t\ttest 0.6447681188583374\n",
      "ACCURACY: \ttrain 0.630088141025641 \t\ttest 0.6297275641025641\n",
      "\n",
      "LOSS: \t\ttrain 0.6670060753822327 \t\ttest 0.6434891223907471\n",
      "ACCURACY: \ttrain 0.6306089743589743 \t\ttest 0.6332131410256411\n",
      "\n",
      "LOSS: \t\ttrain 0.6659842133522034 \t\ttest 0.6424477696418762\n",
      "ACCURACY: \ttrain 0.6337339743589744 \t\ttest 0.6346955128205128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSS: \t\ttrain 0.6647258996963501 \t\ttest 0.6416763067245483\n",
      "ACCURACY: \ttrain 0.6348157051282052 \t\ttest 0.6357371794871794\n",
      "\n",
      "LOSS: \t\ttrain 0.6639215350151062 \t\ttest 0.6405137777328491\n",
      "ACCURACY: \ttrain 0.6364583333333333 \t\ttest 0.6366586538461538\n",
      "\n",
      "LOSS: \t\ttrain 0.662814736366272 \t\ttest 0.6397205591201782\n",
      "ACCURACY: \ttrain 0.6377003205128206 \t\ttest 0.639102564102564\n",
      "\n",
      "LOSS: \t\ttrain 0.6618578433990479 \t\ttest 0.6389337778091431\n",
      "ACCURACY: \ttrain 0.6395432692307692 \t\ttest 0.6387419871794872\n",
      "\n",
      "LOSS: \t\ttrain 0.6607645153999329 \t\ttest 0.6377782225608826\n",
      "ACCURACY: \ttrain 0.6397836538461539 \t\ttest 0.6408253205128205\n",
      "\n",
      "LOSS: \t\ttrain 0.660081148147583 \t\ttest 0.6370208263397217\n",
      "ACCURACY: \ttrain 0.6431490384615385 \t\ttest 0.6434294871794872\n",
      "\n",
      "LOSS: \t\ttrain 0.6589116454124451 \t\ttest 0.6363098621368408\n",
      "ACCURACY: \ttrain 0.6433092948717949 \t\ttest 0.6441105769230769\n",
      "\n",
      "LOSS: \t\ttrain 0.6580570340156555 \t\ttest 0.6345755457878113\n",
      "ACCURACY: \ttrain 0.6451923076923077 \t\ttest 0.6473958333333333\n",
      "\n",
      "LOSS: \t\ttrain 0.656876802444458 \t\ttest 0.6340362429618835\n",
      "ACCURACY: \ttrain 0.6477163461538461 \t\ttest 0.6481570512820513\n",
      "\n",
      "LOSS: \t\ttrain 0.6557141542434692 \t\ttest 0.6330165863037109\n",
      "ACCURACY: \ttrain 0.647676282051282 \t\ttest 0.6488381410256411\n",
      "\n",
      "LOSS: \t\ttrain 0.6548855900764465 \t\ttest 0.633632481098175\n",
      "ACCURACY: \ttrain 0.6483173076923077 \t\ttest 0.6488782051282052\n",
      "\n",
      "LOSS: \t\ttrain 0.6540841460227966 \t\ttest 0.6316813826560974\n",
      "ACCURACY: \ttrain 0.650400641025641 \t\ttest 0.6506410256410257\n",
      "\n",
      "LOSS: \t\ttrain 0.6528880000114441 \t\ttest 0.6310868859291077\n",
      "ACCURACY: \ttrain 0.6510016025641026 \t\ttest 0.6524439102564102\n",
      "\n",
      "LOSS: \t\ttrain 0.6518831253051758 \t\ttest 0.6300781965255737\n",
      "ACCURACY: \ttrain 0.6540064102564103 \t\ttest 0.6534054487179487\n",
      "\n",
      "LOSS: \t\ttrain 0.651116669178009 \t\ttest 0.629723846912384\n",
      "ACCURACY: \ttrain 0.6538461538461539 \t\ttest 0.6539663461538462\n",
      "\n",
      "LOSS: \t\ttrain 0.6501636505126953 \t\ttest 0.6286642551422119\n",
      "ACCURACY: \ttrain 0.6541666666666667 \t\ttest 0.6543269230769231\n",
      "\n",
      "LOSS: \t\ttrain 0.6494338512420654 \t\ttest 0.6280142068862915\n",
      "ACCURACY: \ttrain 0.6558092948717948 \t\ttest 0.6564503205128205\n",
      "\n",
      "LOSS: \t\ttrain 0.6487346887588501 \t\ttest 0.6275613307952881\n",
      "ACCURACY: \ttrain 0.6568509615384616 \t\ttest 0.6567307692307692\n",
      "\n",
      "LOSS: \t\ttrain 0.6481120586395264 \t\ttest 0.6267925500869751\n",
      "ACCURACY: \ttrain 0.6574919871794872 \t\ttest 0.6580929487179488\n",
      "\n",
      "LOSS: \t\ttrain 0.6475954651832581 \t\ttest 0.6266036629676819\n",
      "ACCURACY: \ttrain 0.6585336538461538 \t\ttest 0.6560897435897436\n",
      "\n",
      "LOSS: \t\ttrain 0.6469696760177612 \t\ttest 0.6262511014938354\n",
      "ACCURACY: \ttrain 0.6588541666666666 \t\ttest 0.6561698717948717\n",
      "\n",
      "LOSS: \t\ttrain 0.6464094519615173 \t\ttest 0.6261434555053711\n",
      "ACCURACY: \ttrain 0.6595753205128205 \t\ttest 0.6592548076923077\n",
      "\n",
      "LOSS: \t\ttrain 0.6460064053535461 \t\ttest 0.6255782246589661\n",
      "ACCURACY: \ttrain 0.6607772435897435 \t\ttest 0.6568910256410256\n",
      "\n",
      "LOSS: \t\ttrain 0.6454466581344604 \t\ttest 0.6251956224441528\n",
      "ACCURACY: \ttrain 0.6614583333333334 \t\ttest 0.658213141025641\n",
      "\n",
      "LOSS: \t\ttrain 0.6450045704841614 \t\ttest 0.6249637007713318\n",
      "ACCURACY: \ttrain 0.661738782051282 \t\ttest 0.6590544871794872\n",
      "\n",
      "LOSS: \t\ttrain 0.6445841193199158 \t\ttest 0.6262376308441162\n",
      "ACCURACY: \ttrain 0.6629807692307692 \t\ttest 0.6586538461538461\n",
      "\n",
      "LOSS: \t\ttrain 0.6440446972846985 \t\ttest 0.6243528127670288\n",
      "ACCURACY: \ttrain 0.6631410256410256 \t\ttest 0.6604166666666667\n",
      "\n",
      "LOSS: \t\ttrain 0.6439400315284729 \t\ttest 0.6239680051803589\n",
      "ACCURACY: \ttrain 0.6635016025641025 \t\ttest 0.6602564102564102\n",
      "\n",
      "LOSS: \t\ttrain 0.6435478329658508 \t\ttest 0.6241632699966431\n",
      "ACCURACY: \ttrain 0.6638621794871795 \t\ttest 0.6584535256410257\n",
      "\n",
      "LOSS: \t\ttrain 0.6432679891586304 \t\ttest 0.6236557364463806\n",
      "ACCURACY: \ttrain 0.6636217948717948 \t\ttest 0.661738782051282\n",
      "\n",
      "LOSS: \t\ttrain 0.6429181694984436 \t\ttest 0.6228967308998108\n",
      "ACCURACY: \ttrain 0.6643429487179487 \t\ttest 0.6623798076923076\n",
      "\n",
      "LOSS: \t\ttrain 0.642387866973877 \t\ttest 0.6230428814888\n",
      "ACCURACY: \ttrain 0.6650240384615385 \t\ttest 0.6623798076923076\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mDone.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainAttention(model=FurtherAttention,reg=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The example is  this is a __OOV__ biography of a star of the black and white minstrel __OOV__ a certain dixie boy __OOV__ whether this person ever really existed i __OOV__ __OOV__ but considering the cast lists a certain __OOV__ lasses __OOV__ and roscoe karns playing said character as __OOV__ i assume the man did exist and that this is a white-washed __OOV__ the __OOV__ version of his __OOV__ the __OOV__ such as it __OOV__ follows dixie boy from career heights to depression at the death of his wife in __OOV__ his abandonment of the child to __OOV__ and his return at his __OOV__ sixteenth birthday and stage debut for __OOV__ another forgotten __OOV__ benny __OOV__ plays dixie __OOV__ the man has a lovely baritone voice but no acting talent whatsoever and is a boring lump on __OOV__ gladys george valiantly tries her best to enliven the works to no __OOV__ judy clark does the best impersonation of betty hutton __OOV__ ever seen although i believe she thought she was being __OOV__ the scoring replete with many musical numbers for its short running time of 70 minutes earned a deserved oscar __OOV__ worth a __OOV__\n",
      "********************************\n",
      "The ten words with the most attention are : ['his', 'roscoe', 'works', 'this', 'the', 'did', 'no', 'best', 'assume', 'to']\n"
     ]
    }
   ],
   "source": [
    "savepath = Path(\"attentionfurther.pch\")\n",
    "if savepath.is_file():\n",
    "    with savepath.open(\"rb\") as fp :\n",
    "        state = torch.load(fp)\n",
    "index = 2000\n",
    "\n",
    "def get_attention_words_for_example(index_example,model,folder=foldertext_test,nb_words=10):\n",
    "    example = folder[index_example]\n",
    "    s = \" \".join([id2word[i] for i in example[0]])\n",
    "    embedded_example = padding([example])\n",
    "    print(\"The example is \",s)\n",
    "    print(\"********************************\")\n",
    "    preds, attentions = model(embedded_example[0])\n",
    "    indices_firsts = [torch.argsort(attentions.squeeze(1).squeeze(1)).tolist().index(i) for i in range(nb_words)]\n",
    "    words = [id2word[example[0][i]] for i in indices_firsts]\n",
    "    print(\"The ten words with the most attention are :\",words)\n",
    "get_attention_words_for_example(index,state.model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
